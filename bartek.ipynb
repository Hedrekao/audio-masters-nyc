{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to trim our audio so that we have a clear voice of our actor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\barte\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'_io.BufferedReader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load audio file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m audio_file\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mica.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m first_3_seconds \u001b[38;5;241m=\u001b[39m \u001b[43maudio_file\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m385\u001b[39;49m\u001b[43m]\u001b[49m \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Export audio file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m first_3_seconds\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrimmed_audio.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "\u001b[1;31mTypeError\u001b[0m: '_io.BufferedReader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment \n",
    "\n",
    "# Load audio file\n",
    "audio_file = AudioSegment.from_wav(\"ica.wav\") \n",
    "\n",
    "first_3_seconds = audio_file[:10 * 385] \n",
    "\n",
    "# Export audio file\n",
    "first_3_seconds.export(\"trimmed_audio.wav\", format=\"wav\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get a transcription from our processed audio file. We're going to use the 'whisper-1' model from OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For my last holiday, I did a trip to Poland and a trip to Scotland. So, I started with a trip to Scotland to visit my friend for his wedding. It was a guy called Adam, and he was pretty fun as well. And we moved back to Poland with his girlfriend, who then very quickly became his fiancée. And in Poland...'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "# Initialize OpenAI's client with an api key\n",
    "client = OpenAI(api_key='sk-proj-nhM3IK8eylhHGiqjAeGQT3BlbkFJY91PCIcw6MFr9IBvM2Ah')\n",
    "\n",
    "audio_file= open(\"ica.wav\", \"rb\")\n",
    "transcription = client.audio.transcriptions.create(\n",
    "  model=\"whisper-1\", \n",
    "  file=audio_file\n",
    ")\n",
    "transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Poland and a trip to Scotland. So, I started with a trip to Scotland to visit my friend for his wedding. It was a guy called Adam, and he was pretty fun as well. And we moved back to Poland with his girlfriend, who then very quickly became his fiancée. And in Poland...'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trim string so that first 3 seconds are cut out\n",
    "\n",
    "def remove_first_n_words(text, n):\n",
    "    # Split the string into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Check if there are at least n words\n",
    "    if len(words) < n:\n",
    "        return \"\"  # or return the original text if you prefer\n",
    "    \n",
    "    # Skip the first n words and rejoin the rest\n",
    "    return ' '.join(words[n:])\n",
    "\n",
    "transcription_text = remove_first_n_words(transcription.text, 9)\n",
    "transcription_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error_message\":\"You have reached the maximum number of cloned voices of (1).\",\"error_id\":\"VOICE_CLONING_PACKAGE_LIMIT_REACHED\"}\n"
     ]
    }
   ],
   "source": [
    "# Add new voice to API's provider\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://api.play.ht/api/v2/cloned-voices/instant\"\n",
    "\n",
    "files = { \"sample_file\": (\"trimmed_audio.wav.wav\", open(\"trimmed_audio.wav\", \"rb\"), \"audio/wav\") }\n",
    "payload = { \"voice_name\": \"Bob\" }\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"AUTHORIZATION\": \"94fb497b6c6b4f478ce77c6d072dbe5e\",\n",
    "    \"X-USER-ID\": \"QitPERiad2ViuQlOxRVEzYs15Zf2\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, data=payload, files=files, headers=headers)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new file with the AI voice \n",
    "# Btw it startes after like 3 sec but later on we will combine those 2 so that it sounds good\n",
    "\n",
    "# import the playht SDK\n",
    "from pyht import Client, TTSOptions, Format\n",
    "\n",
    "# Initialize PlayHT API with your credentials\n",
    "client = Client(\"QitPERiad2ViuQlOxRVEzYs15Zf2\", \"94fb497b6c6b4f478ce77c6d072dbe5e\")\n",
    "\n",
    "# configure your stream\n",
    "options = TTSOptions(\n",
    "    # this voice id can be one of our prebuilt voices or your own voice clone id, refer to the`listVoices()` method for a list of supported voices.\n",
    "    voice=\"s3://voice-cloning-zero-shot/17e3cb8c-da47-4924-b525-80d0b8428af7/bob/manifest.json\",\n",
    "\n",
    "    # you can pass any value between 8000 and 48000, 24000 is default\n",
    "    sample_rate=44_100,\n",
    "  \n",
    "    # the generated audio encoding, supports 'raw' | 'mp3' | 'wav' | 'ogg' | 'flac' | 'mulaw'\n",
    "    format=Format.FORMAT_WAV,\n",
    "\n",
    "    # playback rate of generated speech\n",
    "    speed=0.85,\n",
    ")\n",
    "\n",
    "# start streaming!\n",
    "text = transcription_text\n",
    "\n",
    "with open('output_audio.wav', 'wb') as audio_file:\n",
    "    # Start streaming and write chunks to the file\n",
    "    for chunk in client.tts(text=text, voice_engine=\"PlayHT2.0-turbo\", options=options):\n",
    "        audio_file.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def combine_wav_files_diff_params(file1_path, file2_path, output_path):\n",
    "    # Load the first file\n",
    "    sound1 = AudioSegment.from_wav(file1_path)\n",
    "    \n",
    "    # Load the second file\n",
    "    sound2 = AudioSegment.from_wav(file2_path)\n",
    "    \n",
    "    # Combine the two sounds\n",
    "    combined_sounds = sound1 + sound2\n",
    "    \n",
    "    # Export the combined sound to a new file\n",
    "    combined_sounds.export(output_path, format='wav')\n",
    "\n",
    "# Example usage\n",
    "combine_wav_files_diff_params('trimmed_audio.wav', 'output_audio.wav', 'final_one.wav')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
